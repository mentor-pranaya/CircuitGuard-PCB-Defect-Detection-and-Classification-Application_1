# -*- coding: utf-8 -*-
"""3)CircuitGuard_Model_Training_EfficientNet_B4_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1g08c_ZFioGotCEzL14a46simzclFVMRj
"""

!pip -q install timm==1.0.9
import os
import glob
import random
import shutil
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter
from tqdm import tqdm
from PIL import Image
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report, f1_score

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler
from torchvision import transforms
import timm

from google.colab import drive
drive.mount('/content/drive')

DRIVE_ZIP_PATH = "/content/drive/MyDrive/CircuitGuard_Project/defect_crops_final.zip"
MODEL_DIR = "/content/drive/MyDrive/CircuitGuard_Project/models"
os.makedirs(MODEL_DIR, exist_ok=True)
BEST_CHECKPOINT = os.path.join(MODEL_DIR, "circuitguard_efficientnet_b4_v2.pth")

IMG_SIZE = 128
BATCH_SIZE = 32
EPOCHS = 25
LR = 1e-4
NUM_WORKERS = 2
SEED = 42

def set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
set_seed(SEED)

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"‚úÖ Using Device: {DEVICE}")

if not os.path.exists("/content/defect_crops_fixed") and not os.path.exists("/content/Short"):
    print(f"üìÇ Unzipping dataset...")
    if not os.path.exists(DRIVE_ZIP_PATH):
         if os.path.exists("/content/defect_crops_fixed.zip"):
             DRIVE_ZIP_PATH = "/content/defect_crops_fixed.zip"
         else:
             raise FileNotFoundError(f"‚ùå Error: Could not find {DRIVE_ZIP_PATH}. Please upload zip to Drive or Colab.")

    !unzip -q "{DRIVE_ZIP_PATH}" -d /content/
    print("‚úÖ Unzip Complete.")

possible_roots = [
    "/content/defect_crops_fixed",
    "/content/content/defect_crops_fixed",
    "/content"
]

LOCAL_DATA_DIR = None
for root in possible_roots:
    if os.path.exists(os.path.join(root, "Short")):
        LOCAL_DATA_DIR = root
        break

if LOCAL_DATA_DIR is None:
    print("üîç Searching for dataset location...")
    for root, dirs, files in os.walk("/content"):
        if "Short" in dirs:
            LOCAL_DATA_DIR = root
            break

if LOCAL_DATA_DIR:
    print(f"‚úÖ Dataset found at: {LOCAL_DATA_DIR}")
else:
    print("‚ùå ERROR: Could not find dataset folders (Short, Open_circuit, etc.)")
    print("Contents of /content/:", os.listdir("/content"))
    raise FileNotFoundError("Dataset extraction failed. Check the logs above.")

classes = sorted([d for d in os.listdir(LOCAL_DATA_DIR) if os.path.isdir(os.path.join(LOCAL_DATA_DIR, d)) and d in ['Missing_hole', 'Mouse_bite', 'Open_circuit', 'Short', 'Spur', 'Spurious_copper']])
print(f"üìã Classes: {classes}")

all_files = []
all_labels = []
for cls in classes:
    files = glob.glob(os.path.join(LOCAL_DATA_DIR, cls, "*.png"))
    all_files.extend(files)
    all_labels.extend([cls] * len(files))

print(f"üìä Total Dataset Size: {len(all_files)} images")

train_files, val_files, train_labels, val_labels = train_test_split(
    all_files, all_labels, test_size=0.2, stratify=all_labels, random_state=SEED
)
class_to_idx = {c: i for i, c in enumerate(classes)}

class PCBDataset(Dataset):
    def __init__(self, files, labels, transform=None):
        self.files = files
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.files)

    def __getitem__(self, idx):
        path = self.files[idx]
        img = Image.open(path).convert('RGB')
        label = class_to_idx[self.labels[idx]]

        if self.transform:
            img = self.transform(img)
        return img, label

train_tf = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.RandomHorizontalFlip(p=0.5),
    transforms.RandomVerticalFlip(p=0.5),
    transforms.RandomRotation(15),
    transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

val_tf = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])
])

train_ds = PCBDataset(train_files, train_labels, transform=train_tf)
val_ds = PCBDataset(val_files, val_labels, transform=val_tf)

print("‚öñÔ∏è Calculating Sampler Weights...")
train_indices = [class_to_idx[label] for label in train_labels]
class_counts = Counter(train_indices)

weights = []
for i in range(len(classes)):
    c = class_counts[i]
    weight = 1.0 / np.sqrt(c) if c > 0 else 0
    weights.append(weight)

sample_weights = [weights[i] for i in train_indices]
sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)

train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler, num_workers=NUM_WORKERS)
val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)

model = timm.create_model('efficientnet_b4', pretrained=True, num_classes=len(classes))
model = model.to(DEVICE)

criterion = nn.CrossEntropyLoss()
optimizer = optim.Adam(model.parameters(), lr=LR)
scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.2, patience=3)
scaler = torch.amp.GradScaler('cuda')

def train_one_epoch(model, loader):
    model.train()
    total_loss, correct, total = 0, 0, 0

    for imgs, lbls in tqdm(loader, desc="Training", leave=False):
        imgs, lbls = imgs.to(DEVICE), lbls.to(DEVICE)

        optimizer.zero_grad()
        with torch.amp.autocast('cuda'):
            outputs = model(imgs)
            loss = criterion(outputs, lbls)

        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()

        total_loss += loss.item() * imgs.size(0)
        _, preds = outputs.max(1)
        correct += preds.eq(lbls).sum().item()
        total += imgs.size(0)
    return total_loss / total, correct / total

def validate(model, loader):
    model.eval()
    total_loss, correct, total = 0, 0, 0
    all_preds, all_lbls = [], []

    with torch.no_grad():
        for imgs, lbls in tqdm(loader, desc="Validating", leave=False):
            imgs, lbls = imgs.to(DEVICE), lbls.to(DEVICE)

            with torch.amp.autocast('cuda'):
                outputs = model(imgs)
                loss = criterion(outputs, lbls)

            total_loss += loss.item() * imgs.size(0)
            _, preds = outputs.max(1)
            correct += preds.eq(lbls).sum().item()
            total += imgs.size(0)

            all_preds.extend(preds.cpu().numpy())
            all_lbls.extend(lbls.cpu().numpy())

    f1 = f1_score(all_lbls, all_preds, average='macro')
    return total_loss / total, correct / total, f1, all_lbls, all_preds

best_f1 = 0.0
history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}

print("\nüöÄ STARTING TRAINING (EfficientNet-B4)...")
for epoch in range(EPOCHS):
    t_loss, t_acc = train_one_epoch(model, train_loader)
    v_loss, v_acc, v_f1, _, _ = validate(model, val_loader)

    scheduler.step(v_f1)

    history['train_loss'].append(t_loss)
    history['val_loss'].append(v_loss)
    history['train_acc'].append(t_acc)
    history['val_acc'].append(v_acc)

    print(f"Epoch {epoch+1}/{EPOCHS} | Train Loss: {t_loss:.4f} Acc: {t_acc:.4f} | Val Loss: {v_loss:.4f} Acc: {v_acc:.4f} F1: {v_f1:.4f}")

    if v_f1 > best_f1:
        best_f1 = v_f1
        torch.save({'model': model.state_dict(), 'classes': classes}, BEST_CHECKPOINT)
        print(f"‚≠ê Model Saved! (Best F1: {best_f1:.4f})")

print(f"\n‚úÖ Training Complete. Best F1: {best_f1:.4f}")

ckpt = torch.load(BEST_CHECKPOINT)
model.load_state_dict(ckpt['model'])
_, _, _, y_true, y_pred = validate(model, val_loader)

print("\n" + "="*50)
print("FINAL CLASSIFICATION REPORT")
print("="*50)
print(classification_report(y_true, y_pred, target_names=classes, digits=4))

plt.figure(figsize=(10, 8))
cm = confusion_matrix(y_true, y_pred)
sns.heatmap(cm, annot=True, fmt='d', xticklabels=classes, yticklabels=classes, cmap='Blues')
plt.title("Confusion Matrix ")
plt.ylabel('True Label')
plt.xlabel('Predicted Label')
plt.show()

plt.figure(figsize=(12, 5))
plt.subplot(1, 2, 1)
plt.plot(history['train_loss'], label='Train')
plt.plot(history['val_loss'], label='Val')
plt.title('Loss')
plt.legend()
plt.subplot(1, 2, 2)
plt.plot(history['train_acc'], label='Train')
plt.plot(history['val_acc'], label='Val')
plt.title('Accuracy')
plt.legend()
plt.show()


helper_path = os.path.join(MODEL_DIR, "inference_helper.py")
with open(helper_path, "w") as f:
    f.write(f"""
import torch, timm
from PIL import Image
from torchvision import transforms

DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
MODEL_PATH = '{BEST_CHECKPOINT}'
CLASSES = {classes}

transform = transforms.Compose([
    transforms.Resize(({IMG_SIZE}, {IMG_SIZE})),
    transforms.ToTensor(),
    transforms.Normalize([0.485,0.456,0.406], [0.229,0.224,0.225])
])

def load_model():
    model = timm.create_model('efficientnet_b4', pretrained=False, num_classes=len(CLASSES))
    ckpt = torch.load(MODEL_PATH, map_location=DEVICE)
    model.load_state_dict(ckpt['model'])
    model.to(DEVICE).eval()
    return model

def predict(model, img_path):
    img = Image.open(img_path).convert('RGB')
    t = transform(img).unsqueeze(0).to(DEVICE)
    with torch.no_grad():
        out = model(t)
        idx = out.argmax(1).item()
    return CLASSES[idx]
""")
print(f"üìÑ Inference Helper saved to: {helper_path}")
